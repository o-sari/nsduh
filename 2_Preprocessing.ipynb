{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "In this notebook the data is going to be:\n",
    "* feature size reduced\n",
    "* test-train split\n",
    "* train set balanced\n",
    "* missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Robert/miniconda3/envs/stan/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (2515) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57146, 2682)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/NSDUH_2015_RFD_Tab.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Remove Features\n",
    "Only keep the roughly 400 pre-screened features and the computed RFD scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.array(pd.read_excel('data/clean_vars.xlsx')['vars'])\n",
    "columns = np.append(columns,(\"HERRFD\",\"TOTRFD\"))\n",
    "df1 = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57146, 401)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Train-Test Split\n",
    "\n",
    "Simple stratified 80/20 split, use total score for stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.iloc[:,0:399]\n",
    "y = df1.iloc[:,399:401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use binning for stratification\n",
    "bins     = np.linspace(0, 1, 11)\n",
    "y_binned = np.digitize(y.iloc[:,1], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 67689\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y_binned, \n",
    "                                                    test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11430, 401)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Balance Training Data\n",
    "\n",
    "For better training results. \n",
    "We need to balance before imputing (because imputation is expensive), but balancing doesnt support NaNs - so temporary recode them as '77777'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing:\n",
      "RFD = 0: 42882\n",
      "RFD > 0: 2834\n"
     ]
    }
   ],
   "source": [
    "print(\"Before balancing:\")\n",
    "print(\"RFD = 0:\", y_train[y_train.iloc[:,1] == 0].count()[1])\n",
    "print(\"RFD > 0:\", y_train[y_train.iloc[:,1] > 0].count()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(77777);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binned2 = (y_train.iloc[:,1] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance between TOTRFD == 0 and TOTRFD > 0\n",
    "Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "nm1 = NearMiss(version=1)\n",
    "Xy_resampled_nm1, y_resampled_nm1 = nm1.fit_resample(Xy_train, y_train_binned2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5668, 401)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bal = pd.DataFrame(data=Xy_resampled_nm1, columns=df1.columns)\n",
    "y_train_bal = pd.DataFrame(data=Xy_resampled_nm1[:,399:401], columns=df1.columns[399:401])\n",
    "df_train_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After balancing:\n",
      "RFD = 0: 2834\n",
      "RFD > 0: 2834\n"
     ]
    }
   ],
   "source": [
    "print(\"After balancing:\")\n",
    "print(\"RFD = 0:\", y_train_bal[y_train_bal.iloc[:,1] == 0].count()[1])\n",
    "print(\"RFD > 0:\", y_train_bal[y_train_bal.iloc[:,1] > 0].count()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Missing Values\n",
    "\n",
    "We have an amount of codes that bear no information for us, and also our NaNs (77777), first we set everything to NaN again, then we let the multivariate imputation do its job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setToNaN(df_In):\n",
    "    df_Out = df_In\n",
    "    # Replace logically assigned\n",
    "    df_Out = df_Out.replace([81, 981, 9981, 99981], 91)\n",
    "    df_Out = df_Out.replace([83, 983, 9983, 99983], 93)\n",
    "    df_Out = df_Out.replace([89, 989, 9989, 99989], 99)\n",
    "    \n",
    "    # Set everything not of interest to NaN\n",
    "    dropvals = [77777, 85, 985, 9985, 94, 994, 9994, 97, 997, 99997, 98, 998, 9998, \".\"]\n",
    "    df_Out = df_Out.replace(dropvals, np.nan)\n",
    "    \n",
    "    return df_Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace codes without content with nan to prepare imputer\n",
    "df_train_imp = setToNaN(df_train_bal)\n",
    "df_test_imp = setToNaN(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=5, random_state=0, initial_strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation for train (k=5668)\n",
    "df_train_imp = imp.fit_transform(df_train_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation for test (k=11430)\n",
    "df_test_imp = imp.fit_transform(df_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting np array to dataframe\n",
    "df_train_imp0 = pd.DataFrame(data=df_train_imp, columns=df1.columns)\n",
    "df_test_imp0  = pd.DataFrame(data=df_test_imp, columns=df1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_imp0.to_csv(\"data/train_data.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\n",
    "df_test_imp0.to_csv(\"data/test_data.tsv.gz\", sep=\"\\t\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
